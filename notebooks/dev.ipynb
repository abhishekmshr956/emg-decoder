{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d0a644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from emgdecomp.decomposition import EmgDecomposition\n",
    "from emgdecomp.parameters import EmgDecompositionParams\n",
    "\n",
    "from src.utils import load_config\n",
    "from src.data.filter import Filter\n",
    "from src.data.utils import bipolar_conversion, load_data, load_data_deprecated, average_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87590aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94568, 67)\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/Users/johnzhou/research/rumi/data/\"\n",
    "expt_name = \"test_2023-08-19-1953_Closed-Loop-Neurofeedback-Interface\"\n",
    "emg_fname = data_dir + expt_name + \"/data_streams/emg_stream.bin\"\n",
    "filter_fname = data_dir + expt_name + \"/data_streams/filter_stream.bin\"\n",
    "\n",
    "try:\n",
    "    emg_data = load_data(emg_fname)\n",
    "#     filter_data = load_data(filter_fname)\n",
    "except UnicodeDecodeError:\n",
    "    emg_data = load_data_deprecated(emg_fname)\n",
    "#     filter_data = load_data_deprecated(filter_fname)\n",
    "    \n",
    "emgbuffer = emg_data['emgbuffer']\n",
    "# filterbuffer = filter_data['filterbuffer']\n",
    "\n",
    "print(emgbuffer.shape)\n",
    "# print(filterbuffer.shape[0] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e171086",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.num_chans = data.shape[-1]\n",
    "        self.pointer = 0\n",
    "    \n",
    "    def poll(self):\n",
    "        num_samples = int(np.random.rand() * 40 + 40)\n",
    "        if np.random.rand() < 0.05:\n",
    "            return None\n",
    "        \n",
    "        data = self.data[self.pointer:self.pointer + num_samples, :]\n",
    "        self.pointer += num_samples\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8ae4230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Decomposer:\n",
    "#     def __init__(self, filter_buffer, emgde=None):\n",
    "#         self.filter_buffer = filter_buffer\n",
    "#         self.rest_time = 10\n",
    "#         self.init_time = 60\n",
    "#         self.Fs = 2000\n",
    "#         self.num_chans = filter_buffer.num_chans\n",
    "#         self.threshold_factor = 6\n",
    "#         self.dead_time_remaining = 0\n",
    "#         self.threshold_cross_deadtime = int(0.020 * self.Fs)\n",
    "#         self.window_pre = int(0.010 * self.Fs)\n",
    "#         self.window_post = int(0.020 * self.Fs)\n",
    "#         self.decomp_params = EmgDecompositionParams(self.Fs)\n",
    "#         self.num_crossings_to_add_sources = 50\n",
    "#         self.crossings_count_without_detection = 0\n",
    "#         self.crossing_windows_without_detection = np.zeros((self.num_chans, \n",
    "#                                                             self.window_pre + self.window_post, \n",
    "#                                                             self.num_crossings_to_add_sources))\n",
    "#         self.threshold = None\n",
    "#         if emgde is None:\n",
    "#             self.emgde = EmgDecomposition(self.decomp_params)\n",
    "#         else:\n",
    "#             self.emgde = emgde\n",
    "            \n",
    "#         self.decomp_buffer = None\n",
    "#         self.num_firings = 0\n",
    "#         self.num_samples = 0\n",
    "            \n",
    "#     def run(self):\n",
    "#         data = self.filter_buffer.poll()\n",
    "#         if data is None:\n",
    "#             return\n",
    "# #         print(\"Num samples polled:\", data.shape[0])\n",
    "#         self.num_samples += data.shape[0]\n",
    "        \n",
    "#         if self.decomp_buffer is not None:\n",
    "#             data = np.concatenate((self.decomp_buffer, data))\n",
    "# #             print(\"Buffer len:\", self.decomp_buffer.shape[0])\n",
    "# #             print(\"Total data len:\", data.shape[0])\n",
    "#             self.decomp_buffer = None\n",
    "        \n",
    "#         num_samples = data.shape[0]\n",
    "#         threshold_idxs = self.detect_threshold_crossing(data[self.dead_time_remaining:, ...]) + self.dead_time_remaining\n",
    "        \n",
    "#         # If there is not enough samples at the end to create a window around the threshold crossing, leave in the \n",
    "#         #  decomp buffer for the next run\n",
    "#         keep_idxs = np.argwhere(threshold_idxs + self.window_post <= num_samples)\n",
    "#         leave_idxs = np.argwhere(threshold_idxs + self.window_post > num_samples)\n",
    "        \n",
    "#         if leave_idxs.size > 0:\n",
    "# #             print(f\"Leaving {len(leave_idxs)} crossings behind, not enough samples...\")\n",
    "#             leave = threshold_idxs[leave_idxs].flatten()\n",
    "#             self.decomp_buffer = data[int(leave[0]) - self.window_pre:, ...]\n",
    "#         if keep_idxs.size > 0:\n",
    "#             keep = threshold_idxs[keep_idxs].flatten()\n",
    "# #             print(\"Decomposing window around idx\", keep)\n",
    "#             decomp_windows = self.create_windows(data,\n",
    "#                                                  keep,\n",
    "#                                                  self.window_pre, \n",
    "#                                                  self.window_post)\n",
    "#             firings = self.emgde.transform(np.squeeze(decomp_windows))\n",
    "#             self.num_firings += len(firings)\n",
    "#             if len(firings):\n",
    "#                 print(f\"{np.unique(np.array([st[0] for st in firings])).size} sources identified with a \"\n",
    "#               f\"total of {len(firings)} spikes.\")\n",
    "#             else:\n",
    "#                 print(\"No spikes found\")\n",
    "#             num_decomp_windows = decomp_windows.shape[-1]\n",
    "#             if len(firings) == 0:\n",
    "#                 if num_decomp_windows + self.crossings_count_without_detection <= self.num_crossings_to_add_sources:\n",
    "#                     self.crossing_windows_without_detection[...,\n",
    "#                         self.crossings_count_without_detection:self.crossings_count_without_detection + decomp_windows.shape[-1]\n",
    "#                     ] = decomp_windows\n",
    "#                 else:\n",
    "#                     remaining_windows = self.crossings_count_without_detection + num_decomp_windows - self.num_crossings_to_add_sources\n",
    "#                     windows_to_add = np.expand_dims(np.squeeze(decomp_windows[..., 0:remaining_windows]), axis=-1)\n",
    "#                     self.crossing_windows_without_detection[..., self.crossings_count_without_detection:self.num_crossings_to_add_sources] = windows_to_add\n",
    "#                 self.crossings_count_without_detection += decomp_windows.shape[-1]\n",
    "#             if self.crossings_count_without_detection >= self.num_crossings_to_add_sources:\n",
    "#                 print(f\"{self.num_crossings_to_add_sources} threshold crossings without sources id'ed, adding new sources!\")\n",
    "#                 firings = self.emgde.decompose_batch(self.crossing_windows_without_detection)\n",
    "#                 self.num_firings += len(firings)\n",
    "#                 if len(firings):\n",
    "#                     print(f\"{np.unique(np.array([st[0] for st in firings])).size} new sources identified with a \"\n",
    "#                   f\"total of {len(firings)} spikes.\")\n",
    "#                 else:\n",
    "#                     print(\"No new sources found!\")\n",
    "#                 self.crossings_count_without_detection = 0\n",
    "#         if self.decomp_buffer is None:\n",
    "#             self.decomp_buffer = data[-self.window_pre:, ...]\n",
    "#         self.dead_time_remaining = self.window_pre\n",
    "# #         print(\"\\n\")\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def create_windows(data, idxs, window_pre, window_post):\n",
    "#         num_windows = len(idxs)\n",
    "#         num_chans = data.shape[-1]\n",
    "#         window_len = window_pre + window_post\n",
    "        \n",
    "#         windows = np.zeros((num_chans, window_len, num_windows))\n",
    "#         for window_idx, i in enumerate(idxs):\n",
    "# #             print(\"Window start\", i - window_pre, \", end\", i + window_post)\n",
    "#             start = i - window_pre\n",
    "#             end = i + window_post\n",
    "#             if start < 0 or end > data.shape[0]:\n",
    "#                 raise ValueError(\"Not enough samples!\")\n",
    "#             windows[..., window_idx] = data[start:end, ...].T\n",
    "#         return windows\n",
    "        \n",
    "#     def set_threshold(self) -> None:\n",
    "#         print('Setting threshold')\n",
    "#         buffer_len = self.rest_time * self.Fs\n",
    "#         thresholding_buffer = np.zeros((buffer_len, self.num_chans))\n",
    "#         write_pointer = 0\n",
    "#         while write_pointer < buffer_len:\n",
    "#             data = self.filter_buffer.poll()\n",
    "#             if data is not None:\n",
    "#                 num_samples = data.shape[0]\n",
    "#                 if num_samples + write_pointer > buffer_len:\n",
    "#                     remaining_space = buffer_len - write_pointer\n",
    "#                     data = data[:remaining_space]\n",
    "#                 thresholding_buffer[write_pointer:write_pointer + num_samples] = data\n",
    "#                 write_pointer += num_samples\n",
    "\n",
    "#         channel_means = np.mean(thresholding_buffer, axis=0)\n",
    "#         channel_stds = np.std(thresholding_buffer, axis=0)\n",
    "#         self.threshold = channel_means + self.threshold_factor * channel_stds\n",
    "#         print('Threshold set!')\n",
    "\n",
    "#     def detect_threshold_crossing(self, data):\n",
    "#         \"\"\"Detect threshold crossings in the data, return time indices of threshold crossings.\"\"\"\n",
    "#         num_samples = data.shape[0]\n",
    "#         time_idxs, channel_idxs = np.nonzero(data > self.threshold)\n",
    "        \n",
    "#         if time_idxs.size == 0:\n",
    "#             return np.array([])\n",
    "#         else:\n",
    "#             time_idxs = time_idxs  # get correct idxs w.r.t. input\n",
    "\n",
    "#         sorted_time_idxs = np.sort(np.unique(time_idxs))\n",
    "#         alive_idxs = []\n",
    "\n",
    "#         dead_until_idx = -1\n",
    "#         for idx in sorted_time_idxs:\n",
    "#             if idx > dead_until_idx:\n",
    "#                 alive_idxs.append(idx)\n",
    "#                 dead_until_idx = idx + self.threshold_cross_deadtime\n",
    "# #         print(\"Crossing identified at idxs:\", alive_idxs)\n",
    "\n",
    "#         return np.array(alive_idxs)\n",
    "        \n",
    "#     def init_model(self) -> None:\n",
    "#         \"\"\"Initialize the decomposition model on the first num_seconds of data.\"\"\"\n",
    "#         init_buffer = np.zeros((self.init_time * self.Fs, self.num_chans))\n",
    "#         write_pointer = 0\n",
    "        \n",
    "#         while write_pointer < init_buffer.shape[0]:\n",
    "#             data = self.filter_buffer.poll()\n",
    "#             if data is not None:\n",
    "#                 num_samples = data.shape[0]\n",
    "#                 if num_samples + write_pointer > init_buffer.shape[0]:\n",
    "#                     remaining_space = init_buffer.shape[0] - write_pointer\n",
    "#                     data = data[:remaining_space]\n",
    "#                 init_buffer[write_pointer:write_pointer + num_samples] = data\n",
    "#                 write_pointer += num_samples\n",
    "\n",
    "#         # TODO: Need to synchronously empty the buffer while fitting the model, can set\n",
    "#         #  a gamestate flag and let the display empty it\n",
    "#         print(\"Initializing model...\")\n",
    "#         start = time.time()\n",
    "#         firings = self.emgde.decompose(init_buffer.T)\n",
    "#         print(f\"{np.unique(np.array([st[0] for st in firings])).size} sources identified with a \"\n",
    "#               f\"total of {len(firings)} spikes.\")\n",
    "#         print(f\"Took {time.time() - start} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c749cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94568, 67)\n"
     ]
    }
   ],
   "source": [
    "print(emgbuffer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8d2fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "emgde = EmgDecomposition(EmgDecompositionParams)\n",
    "with open('/Users/johnzhou/research/emg_decoder/models/emgde.pkl', 'rb') as f:\n",
    "    emgde = emgde.load(f)\n",
    "print(emgde.num_sources())\n",
    "# emgde.decompose_batch(emgbuffer[:300, 1:32].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1e02d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayStage:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.complete = False\n",
    "        self.code = None\n",
    "    \n",
    "    def run(self, code):\n",
    "        \"\"\"Run behavior may depend on external codes - consider whether to make a new stage instead\"\"\"\n",
    "        if self.complete:\n",
    "            self.exit()\n",
    "        # Do something\n",
    "        self.render()\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def render(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def exit(self):\n",
    "        \"\"\"Set signals and next stage here\"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e0d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecompStage:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.complete = False\n",
    "        \n",
    "    def run(self, data):\n",
    "        \"\"\"Deal with polled data here\"\"\"\n",
    "        if self.complete:\n",
    "            self.exit()\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def exit(self):\n",
    "        \"\"\"Set signals and next stage here\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8046449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decomposer:\n",
    "    def __init__(self, filter_buffer, emgde=None):\n",
    "        self.filter_buffer = filter_buffer\n",
    "        self.game_state = np.zeros(3)\n",
    "        self.rest_time = 10\n",
    "        self.init_time = 60\n",
    "        self.Fs = 2000\n",
    "        self.num_chans = filter_buffer.num_chans\n",
    "        self.threshold_factor = 6\n",
    "        self.dead_time_remaining = 0\n",
    "        self.threshold_cross_deadtime = int(0.020 * self.Fs)\n",
    "        self.window_pre = int(0.010 * self.Fs)\n",
    "        self.window_post = int(0.020 * self.Fs)\n",
    "        self.decomp_params = EmgDecompositionParams(self.Fs)\n",
    "        self.num_crossings_to_add_sources = 50\n",
    "        self.crossings_count_without_detection = 0\n",
    "        self.crossing_windows_without_detection = np.zeros((self.num_chans, \n",
    "                                                            self.window_pre + self.window_post, \n",
    "                                                            self.num_crossings_to_add_sources))\n",
    "        self.threshold = None\n",
    "        if emgde is None:\n",
    "            self.emgde = EmgDecomposition(self.decomp_params)\n",
    "        else:\n",
    "            self.emgde = emgde\n",
    "            \n",
    "        self.decomp_buffer = None\n",
    "        self.num_firings = 0\n",
    "        self.num_samples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "01f27c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting threshold\n",
      "Threshold set!\n"
     ]
    }
   ],
   "source": [
    "filter_buffer = Buffer(filterbuffer[:, :31])\n",
    "module = Decomposer(filter_buffer, emgde=emgde)\n",
    "# module.init_model()\n",
    "module.set_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "13ea6e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 sources identified with a total of 3 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 2 spikes.\n",
      "2 sources identified with a total of 2 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "4 sources identified with a total of 5 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "3 sources identified with a total of 3 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "3 sources identified with a total of 3 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "2 sources identified with a total of 3 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "3 sources identified with a total of 3 spikes.\n",
      "No spikes found\n",
      "2 sources identified with a total of 3 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 2 spikes.\n",
      "3 sources identified with a total of 4 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "3 sources identified with a total of 4 spikes.\n",
      "No spikes found\n",
      "3 sources identified with a total of 4 spikes.\n",
      "No spikes found\n",
      "2 sources identified with a total of 3 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "2 sources identified with a total of 3 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "2 sources identified with a total of 3 spikes.\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "50 threshold crossings without sources id'ed, adding new sources!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnzhou/miniconda3/envs/emg/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/johnzhou/miniconda3/envs/emg/lib/python3.11/site-packages/numpy/core/_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new sources found!\n",
      "1 sources identified with a total of 1 spikes.\n",
      "4 sources identified with a total of 5 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "3 sources identified with a total of 3 spikes.\n",
      "4 sources identified with a total of 4 spikes.\n",
      "No spikes found\n",
      "6 sources identified with a total of 7 spikes.\n",
      "5 sources identified with a total of 6 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "3 sources identified with a total of 4 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "No spikes found\n",
      "2 sources identified with a total of 3 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "3 sources identified with a total of 4 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "4 sources identified with a total of 5 spikes.\n",
      "3 sources identified with a total of 3 spikes.\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "3 sources identified with a total of 5 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "2 sources identified with a total of 2 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "3 sources identified with a total of 5 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "3 sources identified with a total of 3 spikes.\n",
      "4 sources identified with a total of 5 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "2 sources identified with a total of 3 spikes.\n",
      "5 sources identified with a total of 6 spikes.\n",
      "3 sources identified with a total of 4 spikes.\n",
      "3 sources identified with a total of 3 spikes.\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "5 sources identified with a total of 5 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "50 threshold crossings without sources id'ed, adding new sources!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnzhou/miniconda3/envs/emg/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/johnzhou/miniconda3/envs/emg/lib/python3.11/site-packages/numpy/core/_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new sources found!\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "No spikes found\n",
      "3 sources identified with a total of 3 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "2 sources identified with a total of 2 spikes.\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "2 sources identified with a total of 2 spikes.\n",
      "2 sources identified with a total of 2 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "2 sources identified with a total of 2 spikes.\n",
      "2 sources identified with a total of 3 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "2 sources identified with a total of 2 spikes.\n",
      "2 sources identified with a total of 3 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "3 sources identified with a total of 3 spikes.\n",
      "5 sources identified with a total of 7 spikes.\n",
      "6 sources identified with a total of 6 spikes.\n",
      "No spikes found\n",
      "3 sources identified with a total of 3 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "2 sources identified with a total of 2 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "1 sources identified with a total of 2 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "1 sources identified with a total of 3 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "3 sources identified with a total of 3 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "4 sources identified with a total of 4 spikes.\n",
      "3 sources identified with a total of 4 spikes.\n",
      "4 sources identified with a total of 4 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "6 sources identified with a total of 9 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "2 sources identified with a total of 2 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "50 threshold crossings without sources id'ed, adding new sources!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnzhou/miniconda3/envs/emg/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/johnzhou/miniconda3/envs/emg/lib/python3.11/site-packages/numpy/core/_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new sources found!\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "No spikes found\n",
      "3 sources identified with a total of 4 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "3 sources identified with a total of 3 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "3 sources identified with a total of 3 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "2 sources identified with a total of 3 spikes.\n",
      "2 sources identified with a total of 2 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "4 sources identified with a total of 6 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "2 sources identified with a total of 2 spikes.\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n",
      "2 sources identified with a total of 2 spikes.\n",
      "2 sources identified with a total of 2 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "1 sources identified with a total of 1 spikes.\n",
      "No spikes found\n",
      "3 sources identified with a total of 4 spikes.\n",
      "No spikes found\n",
      "No spikes found\n",
      "No spikes found\n"
     ]
    }
   ],
   "source": [
    "for i in range(40000):\n",
    "    module.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cf593812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 7)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emgde._raw_sources.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e967f4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338 94.819\n"
     ]
    }
   ],
   "source": [
    "print(module.num_firings, module.num_samples / 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe957b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
